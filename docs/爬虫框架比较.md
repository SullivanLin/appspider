# 爬虫框架比较

## scrapy VS pySpider

### 比较
* pySpider 调试比 scrapy 简单
* pySpider 文档，社区不如 scrapy 全
* <s>pySpider WebUI 做的比 scrapy 好，支持任务暂停，恢复等</s>**scrapy也支持暂停恢复**
* pySpider 自定义程度比 scrapy 低
* pySPider 的流程没有 scrapy 操作简单
* pySpider 的跨平台 不如 scrapy

### 选择

从当前需求讲，scrapy比pySpider更适合项目。
原因如下：

1. scrapy的流程抽象更合理，更匹配当前的项目需求，当前爬取app应用内数据流程拆分如下：
	1. 分析app接口，提取url，提取控制参数，提炼请求逻辑
	2. 设置请求的url，参数
	3. 发起数据获取请求 \<spider\>
	4. 封装响应数据 \<item\>
	5. 推送爬取的数据 \<pipeline\>  
	3、4、5的过程基本可以采用统一格式，编码过程中，注意约定的方式即可。工作量差不错就停留在1和2上，只要分析清楚，设定好匹配的url和参数即可。
2. scrapy的开发文档更全，稳定性更好
3. scrapy的调度等可以通过scrapyd做定制开发，实现WebUI接口
4. 通用性更好，其他库兼容更好
 
### 注意事项
目前使用scrapy遇到的困难是多级请求不好处理，不过可以将多级请求拆分成两级爬虫的模型，及有写定参数入口的爬虫(统称一级爬虫)和需要传入参数的爬虫(统称二级爬虫)。这样就可以将有逻辑的数据请求全部独立出来，独立开发，预先定义好参数接口即可。例如，一个app首页只返回一个列表，列表中只包含相关视频的基本信息，而要进入视频内部才可以获取到其他的诸如在线人数，评论等信息时，即可拆分成两级爬虫，即一个用于爬列表，一个用于爬视频详细信息，而不用在爬取列表的同时解析数据，再发起下级请求，从而获取详细信息。拆分是必要的，难点在于定义一个统一的参数接口。不过，这个应该可以比较简单的解决。